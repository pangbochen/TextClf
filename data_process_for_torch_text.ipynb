{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset for torchtext\n",
    "\n",
    "in this task, I want too use pytorch torch to build the network, as torch recommanded, I will ue torchtext to load this task's NLP datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load csv file to Pytorch Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First preprocess the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split the validation dataset\n",
    "- handle '\\n' character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data_set\n",
    "val_split = 0.2\n",
    "seed = 666\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace('\\n',' ')\n",
    "test_df = pd.read_csv('data/train.csv')\n",
    "test_df['comment_text'] = test_df['comment_text'].str.replace('\\n',' ')\n",
    "# get validation part\n",
    "idx = np.arange(train_df.shape[0])\n",
    "# set random seed for numpy\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(idx)\n",
    "val_len = int(train_df.shape[0] * val_split)\n",
    "# output dataset\n",
    "output_dir = './data/pre/'\n",
    "train_df.iloc[idx[val_len:], :].to_csv(\"{}/train.csv\".format(output_dir), index=False)\n",
    "train_df.iloc[idx[:val_len], :].to_csv(\"{}/val.csv\".format(output_dir), index=False)\n",
    "test_df.to_csv(\"{}/test.csv\".format(output_dir), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Tokenization the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 100\n",
    "# handle the punctuation of the text work, actually use the re to sub those punctuations\n",
    "# also we could add handle \\n in this function \n",
    "def tokenizer(comment, max_seq_len):\n",
    "    comment = re.sub(\n",
    "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", \n",
    "        str(comment))\n",
    "    comment = re.sub(r\"[ ]+\", \" \", comment)\n",
    "    comment = re.sub(r\"\\!+\", \"!\", comment)\n",
    "    comment = re.sub(r\"\\,+\", \",\", comment)\n",
    "    comment = re.sub(r\"\\?+\", \"?\", comment)\n",
    "    if (len(comment) > max_seq_len):\n",
    "        comment = comment[:max_seq_len]\n",
    "    return [\n",
    "        x.text for x in NLP.tokenizer(comment) if x.text != \" \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above function will return a list of tokens for one comment record. Note the max_seq_len in the opt, the very long comment are trimmed to max_seq_len characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is time to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the torchtext Field, the official guide for the Field\n",
    "    \n",
    "    sequential: Whether the datatype represents sequential data. If False,\n",
    "        no tokenization is applied. Default: True.\n",
    "    use_vocab: Whether to use a Vocab object. If False, the data in this\n",
    "        field should already be numerical. Default: True.\n",
    "    init_token: A token that will be prepended to every example using this\n",
    "        field, or None for no initial token. Default: None.\n",
    "    eos_token: A token that will be appended to every example using this\n",
    "        field, or None for no end-of-sentence token. Default: None.\n",
    "    fix_length: A fixed length that all examples using this field will be\n",
    "        padded to, or None for flexible sequence lengths. Default: None.\n",
    "    dtype: The torch.dtype class that represents a batch of examples\n",
    "        of this kind of data. Default: torch.long.\n",
    "    preprocessing: The Pipeline that will be applied to examples\n",
    "        using this field after tokenizing but before numericalizing. Many\n",
    "        Datasets replace this attribute with a custom preprocessor.\n",
    "        Default: None.\n",
    "    postprocessing: A Pipeline that will be applied to examples using\n",
    "        this field after numericalizing but before the numbers are turned\n",
    "        into a Tensor. The pipeline function takes the batch as a list, and\n",
    "        the field's Vocab.\n",
    "        Default: None.\n",
    "    lower: Whether to lowercase the text in this field. Default: False.\n",
    "    tokenize: The function used to tokenize strings using this field into\n",
    "        sequential examples. If \"spacy\", the SpaCy English tokenizer is\n",
    "        used. Default: str.split.\n",
    "    include_lengths: Whether to return a tuple of a padded minibatch and\n",
    "        a list containing the lengths of each examples, or just a padded\n",
    "        minibatch. Default: False.\n",
    "    batch_first: Whether to produce tensors with the batch dimension first.\n",
    "        Default: False.\n",
    "    pad_token: The string token used as padding. Default: \"<pad>\".\n",
    "    unk_token: The string token used to represent OOV words. Default: \"<unk>\".\n",
    "    pad_first: Do the padding of the sequence at the beginning. Default: False.\n",
    "    truncate_first: Do the truncating of the sequence at the beginning. Defaulf: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f459499291f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m comment_text = data.Field(\n\u001b[0;32m      2\u001b[0m     \u001b[0msequential\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfix_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtokenize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpad_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "comment_text = data.Field(\n",
    "    sequential=True,\n",
    "    fix_length=opt.max_seq_len,\n",
    "    tokenize=tokenizer,\n",
    "    pad_first=True,\n",
    "    lower=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Clft:\n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_doc = NLP(\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "\n",
      "\n",
      "Why\n",
      "the\n",
      "edits\n",
      "made\n",
      "under\n",
      "my\n",
      "username\n",
      "Hardcore\n",
      "Metallica\n",
      "Fan\n",
      "were\n",
      "reverted\n",
      "?\n",
      "They\n",
      "were\n",
      "n't\n",
      "vandalisms\n",
      ",\n",
      "just\n",
      "closure\n",
      "on\n",
      "some\n",
      "GAs\n",
      "after\n",
      "I\n",
      "voted\n",
      "at\n",
      "New\n",
      "York\n",
      "Dolls\n",
      "FAC\n",
      ".\n",
      "And\n",
      "please\n",
      "do\n",
      "n't\n",
      "remove\n",
      "the\n",
      "template\n",
      "from\n",
      "the\n",
      "talk\n",
      "page\n",
      "since\n",
      "I\n",
      "'m\n",
      "retired\n",
      "now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "for i in test_doc:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.vocab.Vocab' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-22ad07c4c821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.vocab.Vocab' object is not callable"
     ]
    }
   ],
   "source": [
    "NLP.vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment = \"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = re.sub(r\"[ ]+\", \" \", comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment = re.sub(\n",
    "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", \n",
    "        str(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_comment_text(comment):\n",
    "    # remove punctuation in comment text\n",
    "    comment = re.sub(r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \",str(comment))\n",
    "    comment = re.sub(r\"\\!+\", \"!\", comment)\n",
    "    comment = re.sub(r\"\\,+\", \",\", comment)\n",
    "    comment = re.sub(r\"\\?+\", \"?\", comment)\n",
    "    comment = re.sub(r\"[ ]+\", \" \", comment)\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits made under my userna...\n",
       "1    D'aww He matches this background colour I'm se...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3     More I can't make any real suggestions on imp...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.comment_text.apply(handle_comment_text).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
